{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/rashmi/Dataset/pre-processed/'\n",
    "labels_df_path = '{}df_iemocap.csv'.format(data_dir)\n",
    "audio_vectors_path = '{}audio_vectors_5.pkl'.format(data_dir)\n",
    "hop_length = 512\n",
    "sr=44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_df_path)\n",
    "audio_vectors = pickle.load(open(audio_vectors_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['wav_file', 'label', 'sig_mean', 'sig_std', 'rmse_mean', 'rmse_std', 'silence', 'harmonic', 'auto_corr_max', 'auto_corr_std','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13']\n",
    "df_features = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {'ang': 0,\n",
    "                'hap': 1,\n",
    "                'exc': 2,\n",
    "                'sad': 3,\n",
    "                'fru': 4,\n",
    "                'fea': 5,\n",
    "                'sur': 6,\n",
    "                'neu': 7,\n",
    "                'xxx': 8,\n",
    "                'oth': 8}\n",
    "\n",
    "data_dir = '/home/madhura/Dataset/pre-processed/'\n",
    "labels_path = '{}df_iemocap.csv'.format(data_dir)\n",
    "audio_vectors_path = '{}audio_vectors_'.format(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1093it [32:16,  1.26s/it]/home/madhura/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/madhura/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/madhura/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/madhura/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/madhura/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "1094it [32:16,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some exception occured\n",
      "Some exception occured\n",
      "Some exception occured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1135it [33:39,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some exception occured\n",
      "Some exception occured\n",
      "Some exception occured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2170it [1:00:09,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "for sess in [5]:\n",
    "        audio_vectors = pickle.load(open('{}{}.pkl'.format(audio_vectors_path, sess), 'rb'))\n",
    "        for index, row in tqdm(labels_df[labels_df['wav_file'].str.contains('Ses0{}'.format(sess))].iterrows()):\n",
    "            try:\n",
    "                wav_file_name = row['wav_file']\n",
    "                label = emotion_dict[row['emotion']]\n",
    "                y = audio_vectors[wav_file_name]\n",
    "\n",
    "                feature_list = [wav_file_name, label]  # wav_file, label\n",
    "                sig_mean = np.mean(abs(y))\n",
    "                feature_list.append(sig_mean)  # sig_mean\n",
    "                feature_list.append(np.std(y))  # sig_std\n",
    "\n",
    "                rmse = librosa.feature.rms(y + 0.0001)[0]\n",
    "                feature_list.append(np.mean(rmse))  # rmse_mean\n",
    "                feature_list.append(np.std(rmse))  # rmse_std\n",
    "\n",
    "                silence = 0\n",
    "                for e in rmse:\n",
    "                    if e <= 0.4 * np.mean(rmse):\n",
    "                        silence += 1\n",
    "                silence /= float(len(rmse))\n",
    "                feature_list.append(silence)  # silence\n",
    "\n",
    "                y_harmonic = librosa.effects.hpss(y)[0]\n",
    "                feature_list.append(np.mean(y_harmonic) * 1000)  # harmonic (scaled by 1000)\n",
    "\n",
    "                # based on the pitch detection algorithm mentioned here:\n",
    "                # http://access.feld.cvut.cz/view.php?cisloclanku=2009060001\n",
    "                cl = 0.45 * sig_mean\n",
    "                center_clipped = []\n",
    "                for s in y:\n",
    "                    if s >= cl:\n",
    "                        center_clipped.append(s - cl)\n",
    "                    elif s <= -cl:\n",
    "                        center_clipped.append(s + cl)\n",
    "                    elif np.abs(s) < cl:\n",
    "                        center_clipped.append(0)\n",
    "                auto_corrs = librosa.core.autocorrelate(np.array(center_clipped))\n",
    "                feature_list.append(1000 * np.max(auto_corrs)/len(auto_corrs))  # auto_corr_max (scaled by 1000)\n",
    "                feature_list.append(np.std(auto_corrs))  # auto_corr_std\n",
    "                \n",
    "                #mfcc \n",
    "                mfccs=np.mean(librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13).T, axis=0)\n",
    "                \n",
    "                for i in range(0,13):\n",
    "                    feature_list.append(mfccs[i])  # mfcc \n",
    "\n",
    "                df_features = df_features.append(pd.DataFrame(feature_list, index=columns).transpose(), ignore_index=True)\n",
    "            except:\n",
    "                print('Some exception occured')\n",
    "\n",
    "df_features.to_csv('/home/madhura/Dataset/pre-processed/audio_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
