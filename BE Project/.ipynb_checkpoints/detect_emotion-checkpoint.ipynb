{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.2050814e-05 6.5532317e-06\n",
      " 0.0000000e+00]\n",
      "0 352800\n",
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.2050814e-05 6.5532317e-06\n",
      " 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "wav_file_path = '/home/rashmi/Dataset/pre-processed/single_file/test_wav/ses05f_impro08_edited.wav'\n",
    "\n",
    "orig_wav_vector, _sr = librosa.load(wav_file_path, sr=sr)\n",
    "orig_wav_vector, _sr\n",
    "\n",
    "start_time = 0\n",
    "end_time = 8\n",
    "start_frame = math.floor(start_time * sr)\n",
    "end_frame = math.floor(end_time * sr)\n",
    "\n",
    "print (orig_wav_vector)\n",
    "print (start_frame,end_frame)\n",
    "\n",
    "truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "print (truncated_wav_vector)\n",
    "\n",
    "truncated_wav_file_name= \"Ses05F_impro08\"\n",
    "audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "\n",
    "with open('/home/acer/Dataset/pre-processed/single_file/audio_vectors.pkl', 'wb') as f:\n",
    "        pickle.dump(audio_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import math\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_vectors_path = '/home/acer/Dataset/pre-processed/single_file/audio_vectors.pkl'\n",
    "audio_vectors = pickle.load(open(audio_vectors_path, 'rb'))\n",
    "random_file_name = list(audio_vectors.keys())[random.choice(range(len(audio_vectors.keys())))]\n",
    "y = audio_vectors[random_file_name]\n",
    "sr = 44100\n",
    "\n",
    "feature_list = [random_file_name];\n",
    "sig_mean = np.mean(abs(y))\n",
    "feature_list.append(sig_mean)  # sig_mean\n",
    "feature_list.append(np.std(y))  # sig_std\n",
    "\n",
    "rms = librosa.feature.rms(y + 0.0001)[0]\n",
    "feature_list.append(np.mean(rms))  # rms_mean\n",
    "feature_list.append(np.std(rms))  # rms_std\n",
    "\n",
    "silence = 0\n",
    "for e in rms:\n",
    "    if e <= 0.4 * np.mean(rms):\n",
    "        silence += 1\n",
    "silence /= float(len(rms))\n",
    "feature_list.append(silence)  # silence\n",
    "\n",
    "y_harmonic = librosa.effects.hpss(y)[0]\n",
    "feature_list.append(np.mean(y_harmonic) * 1000)  # harmonic (scaled by 1000)\n",
    "\n",
    "# based on the pitch detection algorithm mentioned here:\n",
    "# http://access.feld.cvut.cz/view.php?cisloclanku=2009060001\n",
    "cl = 0.45 * sig_mean\n",
    "center_clipped = []\n",
    "for s in y:\n",
    "    if s >= cl:\n",
    "        center_clipped.append(s - cl)\n",
    "    elif s <= -cl:\n",
    "        center_clipped.append(s + cl)\n",
    "    elif np.abs(s) < cl:\n",
    "        center_clipped.append(0)\n",
    "auto_corrs = librosa.core.autocorrelate(np.array(center_clipped))\n",
    "feature_list.append(1000 * np.max(auto_corrs)/len(auto_corrs))  # auto_corr_max (scaled by 1000)\n",
    "feature_list.append(np.std(auto_corrs))  # auto_corr_std\n",
    "\n",
    "columns = ['wav_file', 'sig_mean', 'sig_std', 'rmse_mean', 'rmse_std', 'silence', 'harmonic', 'auto_corr_max', 'auto_corr_std']\n",
    "df_features = pd.DataFrame(columns=columns)\n",
    "\n",
    "df_features = df_features.append(pd.DataFrame(feature_list, index=columns).transpose(), ignore_index=True)\n",
    "\n",
    "df_features.to_csv('/home/acer/Dataset/pre-processed/single_file/audio_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import itertools\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1704, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv('/home/acer/Dataset/pre-processed/s2e/audio_train.csv')\n",
    "x_test = pd.read_csv('/home/acer/Dataset/pre-processed/s2e/audio_test.csv')\n",
    "\n",
    "print(x_train.shape)\n",
    "y_train = x_train['label']\n",
    "y_test = x_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1704, 10) (426, 10)\n",
      "{2: 508, 1: 357, 5: 297, 3: 242, 4: 165, 0: 135}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "cl_weight = dict(pd.Series(x_train['label']).value_counts(normalize=True))\n",
    "print(dict(pd.Series(x_train['label']).value_counts()))\n",
    "\n",
    "del x_train['label']\n",
    "del x_test['label']\n",
    "del x_train['wav_file']\n",
    "del x_test['wav_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sig_mean   sig_std  rmse_mean  rmse_std   silence  harmonic  auto_corr_max  \\\n",
      "0  0.005265  0.011528   0.006644   0.00942  0.497545 -0.008835        0.11198   \n",
      "\n",
      "   auto_corr_std  \n",
      "0        0.56888  \n"
     ]
    }
   ],
   "source": [
    "x_test_new=pd.read_csv('/home/acer/Dataset/pre-processed/single_file/audio_features.csv')\n",
    "del x_test_new['wav_file']\n",
    "print (x_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {'ang': 0,\n",
    "                'hap': 1,\n",
    "                'sad': 2,\n",
    "                'fea': 3,\n",
    "                'sur': 4,\n",
    "                'neu': 5}\n",
    "\n",
    "emo_keys = list(['ang', 'hap', 'sad', 'fea', 'sur', 'neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10319796 0.23286024 0.38086524 0.062769   0.11616904 0.10413853]]\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=1200, min_samples_split=25)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "pred_probs = rf_classifier.predict_proba(x_test_new)\n",
    "\n",
    "print (pred_probs)\n",
    "\n",
    "np.savetxt('/home/acer/Dataset/pre-processed/emo_val/rf.csv',pred_probs,delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
