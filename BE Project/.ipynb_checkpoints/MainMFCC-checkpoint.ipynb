{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa                          #for loading music and audio analysis\n",
    "import os\n",
    "import soundfile as sf                  #read and write sound files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt        #work like matlab\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm                  #progress \n",
    "import pickle                       #python object serialization\n",
    "\n",
    "import IPython.display              #display python object in all front ends\n",
    "import librosa.display              #\n",
    "ms.use('seaborn-muted')             #seaborn-muted is style\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "import wave\n",
    "import contextlib\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_duration\n",
    "columns = ['wav_file','start_time','end_time','label']  #used for time_slot.csv\n",
    "df_time = pd.DataFrame(columns=columns)\n",
    "time_list = []\n",
    "wav_array = []  #used for before_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 30.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#calulate_duration\n",
    "wav_file_path = '/home/rashmi/Dataset/single_file/wav/'\n",
    "orig_wav_files = os.listdir(wav_file_path)\n",
    "for orig_wav_file in tqdm(orig_wav_files):\n",
    "        try:\n",
    "            fname = wav_file_path + orig_wav_file;\n",
    "            wav_array.append(orig_wav_file)\n",
    "            with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "                frames = f.getnframes()\n",
    "                rate = f.getframerate()\n",
    "                duration = frames / float(rate)\n",
    "                time_list = [orig_wav_file,'0',duration,'']\n",
    "                \n",
    "                df_time = df_time.append(pd.DataFrame(time_list, index=columns).transpose(), ignore_index=True)\n",
    "                \n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "\n",
    "df_time.to_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/time_slot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_wav_array=len(wav_array) #for before_final.csv\n",
    "labels_df = pd.read_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/time_slot.csv')\n",
    "iemocap_dir = '/home/rashmi/Dataset/single_file/wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#find audio_vectors and store into pickel file\n",
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "wav_file_path = '/home/rashmi/Dataset/single_file/wav/'\n",
    "orig_wav_files = os.listdir(wav_file_path)\n",
    "for orig_wav_file in tqdm(orig_wav_files):\n",
    "        try:\n",
    "            orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "            orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "            for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "                start_time, end_time, truncated_wav_file_name= row['start_time'], row['end_time'], row['wav_file']\n",
    "                start_frame = math.floor(start_time * sr)\n",
    "                end_frame = math.floor(end_time * sr)\n",
    "                truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "                audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "with open('/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(audio_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = '/home/rashmi/Dataset/single_file/pre-processed-mfcc/time_slot.csv'\n",
    "audio_vectors_path = '/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_vectors.pkl'\n",
    "labels_df = pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['wav_file', 'label', 'sig_mean', 'sig_std', 'rmse_mean', 'rmse_std', 'silence', 'harmonic', 'auto_corr_max', 'auto_corr_std','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13']\n",
    "#df_features = pd.DataFrame(columns=columns)\n",
    "df_features = pd.DataFrame([data], columns = ['wav_file', 'label', 'sig_mean', 'sig_std', 'rmse_mean', 'rmse_std', 'silence', 'harmonic', 'auto_corr_max', 'auto_corr_std','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (22, 1), indices imply (23, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:08,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (22, 1), indices imply (23, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:11,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (22, 1), indices imply (23, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:17,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (22, 1), indices imply (23, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:21,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of passed values is (22, 1), indices imply (23, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#find audio_vectors and store in audio_vectors.csv\n",
    "audio_vectors = pickle.load(open('/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_vectors.pkl', 'rb'))\n",
    "for index, row in tqdm(labels_df[labels_df['wav_file'].str.contains('')].iterrows()):\n",
    "            try:\n",
    "                wav_file_name = row['wav_file']\n",
    "                y = audio_vectors[wav_file_name]\n",
    "\n",
    "                feature_list = [wav_file_name]  # wav_file, label\n",
    "                sig_mean = np.mean(abs(y))\n",
    "                feature_list.append(sig_mean)  # sig_mean\n",
    "                feature_list.append(np.std(y))  # sig_std\n",
    "\n",
    "                rms = librosa.feature.rms(y + 0.0001)[0]\n",
    "                feature_list.append(np.mean(rms))  # rms_mean\n",
    "                feature_list.append(np.std(rms))  # rms_std\n",
    "\n",
    "                silence = 0\n",
    "                for e in rms:\n",
    "                    if e <= 0.4 * np.mean(rms):\n",
    "                        silence += 1\n",
    "                silence /= float(len(rms))\n",
    "                feature_list.append(silence)  # silence\n",
    "\n",
    "                y_harmonic = librosa.effects.hpss(y)[0]\n",
    "                feature_list.append(np.mean(y_harmonic) * 1000)  # harmonic (scaled by 1000)\n",
    "\n",
    "                # based on the pitch detection algorithm mentioned here:\n",
    "                # http://access.feld.cvut.cz/view.php?cisloclanku=2009060001\n",
    "                cl = 0.45 * sig_mean\n",
    "                center_clipped = []\n",
    "                for s in y:\n",
    "                    if s >= cl:\n",
    "                        center_clipped.append(s - cl)\n",
    "                    elif s <= -cl:\n",
    "                        center_clipped.append(s + cl)\n",
    "                    elif np.abs(s) < cl:\n",
    "                        center_clipped.append(0)\n",
    "                auto_corrs = librosa.core.autocorrelate(np.array(center_clipped))\n",
    "                feature_list.append(1000 * np.max(auto_corrs)/len(auto_corrs))  # auto_corr_max (scaled by 1000)\n",
    "                feature_list.append(np.std(auto_corrs))  # auto_corr_std\n",
    "\n",
    "                #mfcc \n",
    "                mfccs=np.mean(librosa.feature.mfcc(y=y, sr=sr, hop_length=512, n_mfcc=13).T, axis=0)\n",
    "                \n",
    "                for i in range(0,13):\n",
    "                    feature_list.append(mfccs[i])  # mfcc \n",
    "                    \n",
    "                    \n",
    "                df_features = df_features.append(pd.DataFrame(feature_list, index=columns).transpose(), ignore_index=True)\n",
    "            except Exception as e: print(e)\n",
    "\n",
    "df_features.to_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
