{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa                          #for loading music and audio analysis\n",
    "import os\n",
    "import soundfile as sf                  #read and write sound files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt        #work like matlab\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm                  #progress \n",
    "import pickle                       #python object serialization\n",
    "\n",
    "import IPython.display              #display python object in all front ends\n",
    "import librosa.display              #\n",
    "ms.use('seaborn-muted')             #seaborn-muted is style\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "import wave\n",
    "import contextlib\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['wav_file','start_time','end_time','label']\n",
    "df_time = pd.DataFrame(columns=columns)\n",
    "time_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 35.24it/s]\n"
     ]
    }
   ],
   "source": [
    "wav_file_path = '/home/rashmi/Dataset/single_file/wav/'\n",
    "orig_wav_files = os.listdir(wav_file_path)\n",
    "for orig_wav_file in tqdm(orig_wav_files):\n",
    "        try:\n",
    "            fname = wav_file_path + orig_wav_file;\n",
    "            with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "                frames = f.getnframes()\n",
    "                rate = f.getframerate()\n",
    "                duration = frames / float(rate)\n",
    "                time_list = [orig_wav_file,'0',duration,'']\n",
    "                \n",
    "                df_time = df_time.append(pd.DataFrame(time_list, index=columns).transpose(), ignore_index=True)\n",
    "                \n",
    "        except:\n",
    "              print('An exception occured for {}'.format(orig_wav_file))\n",
    "\n",
    "df_time.to_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/time_slot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/time_slot.csv')\n",
    "iemocap_dir = '/home/rashmi/Dataset/single_file/wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['wav_file','start_time','end_time','label']\n",
    "df_time = pd.DataFrame(columns=columns)\n",
    "time_list = []\n",
    "wav_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "wav_file_path = '/home/rashmi/Dataset/single_file/wav/'\n",
    "orig_wav_files = os.listdir(wav_file_path)\n",
    "for orig_wav_file in tqdm(orig_wav_files):\n",
    "        try:\n",
    "            orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "            wav_array.append(orig_wav_file)\n",
    "            orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "            for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "                start_time, end_time, truncated_wav_file_name= row['start_time'], row['end_time'], row['wav_file']\n",
    "                start_frame = math.floor(start_time * sr)\n",
    "                end_frame = math.floor(end_time * sr)\n",
    "                truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "                audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "with open('/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(audio_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ses05M_script02_2_F034.wav', 'ses05m_impro06_M004.wav', 'Ses05f_impro08_F022.wav', 'Ses05F_impro08_F007.wav', 'Ses05F_impro01_F013.wav']\n"
     ]
    }
   ],
   "source": [
    "print(wav_array)\n",
    "len_wav_array=len(wav_array)\n",
    "labels_df = pd.read_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/time_slot.csv')\n",
    "iemocap_dir = '/home/rashmi/Dataset/single_file/wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = '/home/rashmi/Dataset/single_file/pre-processed-mfcc/time_slot.csv'\n",
    "audio_vectors_path = '/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_vectors.pkl'\n",
    "labels_df = pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['wav_file', 'sig_mean', 'sig_std', 'rmse_mean', 'rmse_std', 'silence', 'harmonic', 'auto_corr_max', 'auto_corr_std','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13']\n",
    "df_features = pd.DataFrame(columns=columns)\n",
    "hop_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:23,  4.66s/it]\n"
     ]
    }
   ],
   "source": [
    "audio_vectors = pickle.load(open('/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_vectors.pkl', 'rb'))\n",
    "for index, row in tqdm(labels_df[labels_df['wav_file'].str.contains('')].iterrows()):\n",
    "            try:\n",
    "                wav_file_name = row['wav_file']\n",
    "                y = audio_vectors[wav_file_name]\n",
    "\n",
    "                feature_list = [wav_file_name]  # wav_file, label\n",
    "                sig_mean = np.mean(abs(y))\n",
    "                feature_list.append(sig_mean)  # sig_mean\n",
    "                feature_list.append(np.std(y))  # sig_std\n",
    "\n",
    "                rms = librosa.feature.rms(y + 0.0001)[0]\n",
    "                feature_list.append(np.mean(rms))  # rms_mean\n",
    "                feature_list.append(np.std(rms))  # rms_std\n",
    "\n",
    "                silence = 0\n",
    "                for e in rms:\n",
    "                    if e <= 0.4 * np.mean(rms):\n",
    "                        silence += 1\n",
    "                silence /= float(len(rms))\n",
    "                feature_list.append(silence)  # silence\n",
    "\n",
    "                y_harmonic = librosa.effects.hpss(y)[0]\n",
    "                feature_list.append(np.mean(y_harmonic) * 1000)  # harmonic (scaled by 1000)\n",
    "\n",
    "                # based on the pitch detection algorithm mentioned here:\n",
    "                # http://access.feld.cvut.cz/view.php?cisloclanku=2009060001\n",
    "                cl = 0.45 * sig_mean\n",
    "                center_clipped = []\n",
    "                for s in y:\n",
    "                    if s >= cl:\n",
    "                        center_clipped.append(s - cl)\n",
    "                    elif s <= -cl:\n",
    "                        center_clipped.append(s + cl)\n",
    "                    elif np.abs(s) < cl:\n",
    "                        center_clipped.append(0)\n",
    "                auto_corrs = librosa.core.autocorrelate(np.array(center_clipped))\n",
    "                feature_list.append(1000 * np.max(auto_corrs)/len(auto_corrs))  # auto_corr_max (scaled by 1000)\n",
    "                feature_list.append(np.std(auto_corrs))  # auto_corr_std\n",
    "\n",
    "                #mfcc \n",
    "                mfccs=np.mean(librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13).T, axis=0)\n",
    "                \n",
    "                for i in range(0,13):\n",
    "                    feature_list.append(mfccs[i])  # mfcc \n",
    "                    \n",
    "                df_features = df_features.append(pd.DataFrame(feature_list, index=columns).transpose(), ignore_index=True)\n",
    "            except Exception as e: print(e)\n",
    "\n",
    "df_features.to_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import itertools\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1704, 23)\n",
      "(1704, 21) (5, 21)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv('/home/rashmi/Dataset/pre-processed-mfcc/s2e/audio_train.csv')\n",
    "x_test = pd.read_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/audio_features.csv')\n",
    "\n",
    "print(x_train.shape)\n",
    "y_train = x_train['label']\n",
    "\n",
    "del x_train['label']\n",
    "del x_train['wav_file']\n",
    "del x_test['wav_file']\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {'ang': 0,\n",
    "                'hap': 1,\n",
    "                'sad': 2,\n",
    "                'fea': 3,\n",
    "                'sur': 4,\n",
    "                'neu': 5}\n",
    "\n",
    "emo_keys = list(['ang', 'hap', 'sad', 'fea', 'sur', 'neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=1200, min_samples_split=25)\n",
    "xgb_classifier = xgb.XGBClassifier(max_depth=7, learning_rate=0.008, objective='multi:softprob', \n",
    "                                   n_estimators=1200, sub_sample=0.8, num_class=len(emotion_dict),\n",
    "                                   booster='gbtree', n_jobs=4)\n",
    "mnb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02598576 0.0575399  0.05910216 0.00634903 0.80682313 0.0442    ]\n",
      " [0.0934111  0.28716817 0.26363334 0.01930444 0.06782994 0.268653  ]\n",
      " [0.26227564 0.14029042 0.2963485  0.00386859 0.03140042 0.26581645]\n",
      " [0.02413877 0.0914949  0.07761557 0.6298246  0.02348149 0.15344477]\n",
      " [0.05900431 0.26729223 0.15410924 0.00298566 0.1915403  0.32506824]]\n"
     ]
    }
   ],
   "source": [
    "#eclf1 = VotingClassifier(estimators=[('rf', rf_classifier), ('xgb', xgb_classifier), ('mnb', mnb_classifier)], voting='soft')\n",
    "eclf1 = xgb_classifier.fit(x_train, y_train)\n",
    "pred_probs=eclf1.predict_proba(x_test)\n",
    "\n",
    "#with open('/home/rashmi/Dataset/single_file/xgb_classifier.pkl', 'rb') as file:  \n",
    " #   Pickled_Model = pickle.load(file)\n",
    "    \n",
    "#pred_probs=Pickled_Model.predict_proba(x_test)\n",
    "\n",
    "print(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sur\n",
      "hap\n",
      "sad\n",
      "fea\n",
      "neu\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "emo_array=[]\n",
    "range1 = len(pred_probs)\n",
    "for x in range(0,range1):\n",
    "    index = pred_probs[x].argmax(axis=0).item()\n",
    "    emo_array.append(emo_keys[index]);\n",
    "    print(emo_keys[index]) \n",
    "print(len_wav_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['wav_file','emotions','value']\n",
    "df_features = pd.DataFrame(columns=columns)\n",
    "for a in range(0,len_wav_array):\n",
    "    try :\n",
    "        feature_list =[wav_array[a]]\n",
    "        feature_list.append(emo_array[a])\n",
    "        #feature_list =[emo_array[a]]\n",
    "        if emo_array[a] == \"ang\" :\n",
    "            feature_list.append(0)\n",
    "        elif emo_array[a] == \"fea\" :\n",
    "            feature_list.append(1)\n",
    "        elif emo_array[a] == \"sad\" :\n",
    "            feature_list.append(2)\n",
    "        elif emo_array[a] == \"sur\" :\n",
    "            feature_list.append(3)\n",
    "        elif emo_array[a] == \"neu\" :\n",
    "            feature_list.append(4)\n",
    "        elif emo_array[a] == \"happy\" :\n",
    "            feature_list.append(5)\n",
    "        else :\n",
    "            feature_list.append(6)\n",
    "        \n",
    "        df_features = df_features.append(pd.DataFrame(feature_list, index=columns).transpose(), ignore_index=True)\n",
    "    except :\n",
    "        print(\"Error while making csv\");\n",
    "\n",
    "df_features.to_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/before_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_file</th>\n",
       "      <th>emotions</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ses05F_impro08_F007.wav</td>\n",
       "      <td>fea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Ses05f_impro08_F022.wav</td>\n",
       "      <td>sad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ses05M_script02_2_F034.wav</td>\n",
       "      <td>sur</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ses05F_impro01_F013.wav</td>\n",
       "      <td>neu</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ses05m_impro06_M004.wav</td>\n",
       "      <td>hap</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wav_file emotions  value\n",
       "3     Ses05F_impro08_F007.wav      fea      1\n",
       "2     Ses05f_impro08_F022.wav      sad      2\n",
       "0  Ses05M_script02_2_F034.wav      sur      3\n",
       "4     Ses05F_impro01_F013.wav      neu      4\n",
       "1     ses05m_impro06_M004.wav      hap      6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prioritize \n",
    "df= pd.read_csv('/home/rashmi/Dataset/single_file/pre-processed-mfcc/before_final.csv')\n",
    "result = df.sort_values('value')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
