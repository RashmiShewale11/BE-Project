{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.8725461e-02, -1.7688915e-01, -3.2697320e-01, ...,\n",
       "        -6.8385350e-05, -2.4055229e-05,  0.0000000e+00], dtype=float32), 44100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/home/rashmi/Dataset/IEMOCAP_full_release/Session5/dialog/wav/Ses05F_impro01.wav'\n",
    "\n",
    "y, sr = librosa.load(file_path, sr=44100)\n",
    "y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "labels_df = pd.read_csv('/home/rashmi/Dataset/pre-processed-chromagram/df_iemocap.csv')\n",
    "iemocap_dir = '/home/rashmi/Dataset/IEMOCAP_full_release/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "for sess in [5]:  # using one session due to memory constraint, can replace [5] with range(1, 6)\n",
    "    wav_file_path = '{}Session{}/dialog/wav/'.format(iemocap_dir, sess)\n",
    "    orig_wav_files = os.listdir(wav_file_path)\n",
    "    for orig_wav_file in tqdm(orig_wav_files):\n",
    "        try:\n",
    "            orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "            orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "            for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "                start_time, end_time, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row['end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n",
    "                start_frame = math.floor(start_time * sr)\n",
    "                end_frame = math.floor(end_time * sr)\n",
    "                truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "                audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "    with open('/home/rashmi/Dataset/pre-processed-chromagram/audio_vectors_{}.pkl'.format(sess), 'wb') as f:\n",
    "        pickle.dump(audio_vectors, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
